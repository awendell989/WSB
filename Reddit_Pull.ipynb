{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sqlalchemy \n",
    "import psycopg2\n",
    "import smtplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 10, 1, 0, 0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company = 'GAME_STOP'\n",
    "keyword = '\"Game Stop\"'\n",
    "date_str = '2020-10-01'\n",
    "date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PushShiftPull():\n",
    "    def _init_(keyword,last_comment,last_submmision,company):\n",
    "        self.company = company\n",
    "        self.keyword = keyword\n",
    "        self.last_comment = last_comment\n",
    "        self.last_submission = last_submission\n",
    "    def create_directories(self):\n",
    "        def check_create(directory):\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "        #Topline\n",
    "        self.directory = os.path.join(os.getcwd(),'Reddit_Content',self.company,self.keyword)\n",
    "        check_create(self.directory)\n",
    "        #Comments\n",
    "        self.directory_comments = os.path.join(self.directory,'comments')\n",
    "        check_create(self.directory_comments)\n",
    "        #Posts\n",
    "        self.directory_posts = os.path.join(self.directory,'posts')\n",
    "        check_create(self.directory_posts)\n",
    "    def downloadFromUrl_comment(self):\n",
    "        last_comment_timestamp = int(self.last_comment.timestamp())\n",
    "        #print(last_comment_timestamp)\n",
    "        #url = \"https://api.pushshift.io/reddit/comment/search?q={}&after={}&limit=1000&sort=desc&before=\".format(self.keyword,self.comment_max)\n",
    "        url = \"https://api.pushshift.io/reddit/comment/search?q={}&limit=1000&subreddit=wallstreetbets&sort=desc&after={}&before=\".format(self.keyword,last_comment_timestamp )\n",
    "        print(url)\n",
    "        count = 0\n",
    "        previous_epoch = int(datetime.utcnow().timestamp())\n",
    "        dfs = []\n",
    "        while True:\n",
    "            #new_url = url+str(previous_epoch)\n",
    "            new_url = url.format(self.keyword,last_comment_timestamp)+str(previous_epoch)\n",
    "            print(new_url)\n",
    "            json = requests.get(new_url, headers={'User-Agent': \"Post downloader by /u/Watchful1\"})\n",
    "            try:\n",
    "                json_data = json.json()\n",
    "            except:\n",
    "                print('failed!')\n",
    "                break\n",
    "            if 'data' not in json_data:\n",
    "                break\n",
    "            objects = json_data['data']\n",
    "            if len(objects) == 0:\n",
    "                break\n",
    "            print('no break')\n",
    "            for object in objects:\n",
    "                previous_epoch = object['created_utc'] - 1\n",
    "                count += 1\n",
    "                try:\n",
    "                    if count == 1:\n",
    "                        self.comment_df = json_normalize(object)\n",
    "                    else:\n",
    "                        df = json_normalize(object)\n",
    "                        self.comment_df = pd.concat([self.comment_df,df],axis = 0,ignore_index = True,sort=False)\n",
    "                except Exception as err:\n",
    "                    print(f\"Couldn't print comment: https://www.reddit.com{object['permalink']}\")\n",
    "                    print(traceback.format_exc())\n",
    "            print(\"Saved {} comments through {}\".format(count, datetime.fromtimestamp(previous_epoch).strftime(\"%Y-%m-%d\")))\n",
    "        try:\n",
    "            #self.comment_df = pd.concat(dfs,axis = 0,ignore_index = True,sort=False)\n",
    "            self.comment_df['created_utc'] = pd.to_datetime(self.comment_df['created_utc'],unit='s')\n",
    "            self.comment_df['type'] = 'comment'\n",
    "            columns = ['author','author_fullname','body','created_utc','id','link_id','parent_id','permalink','score','subreddit','subreddit_id','subreddit_name_prefixed','subreddit_type','total_awards_received','type']\n",
    "            self.comment_df = self.comment_df.reindex(columns = columns)\n",
    "            #self.comment_df.to_csv(self.filename_comments,index = False)\n",
    "        except:\n",
    "            print('Not comments for ' + str(self.keyword))\n",
    "    def downloadFromUrl_submission(self):\n",
    "        #url = \"https://api.pushshift.io/reddit/submission/search?q={}&after={}&limit=1000&sort=desc&author=&before=\".format(self.keyword,self.submission_max)\n",
    "        #print(url)\n",
    "        last_sumbission = int(self.last_submission.timestamp())\n",
    "        url = \"https://api.pushshift.io/reddit/submission/search?q={}&limit=1000&subreddit=wallstreetbets&sort=desc&author=&after={}&before=\".format(self.keyword,last_sumbission)\n",
    "        count = 0\n",
    "        previous_epoch = int(datetime.utcnow().timestamp())\n",
    "        dfs = []\n",
    "        while True:\n",
    "            new_url = url.format(self.keyword,last_sumbission)+str(previous_epoch)\n",
    "            json = requests.get(new_url, headers={'User-Agent': \"Post downloader by /u/Watchful1\"})\n",
    "            print('got json')\n",
    "            try:\n",
    "                json_data = json.json()\n",
    "            except:\n",
    "                print('failed!')\n",
    "                break\n",
    "            if 'data' not in json_data:\n",
    "                break\n",
    "            objects = json_data['data']\n",
    "            if len(objects) == 0:\n",
    "                break\n",
    "            for object in objects:\n",
    "                previous_epoch = object['created_utc'] - 1\n",
    "                count += 1\n",
    "                #if object['is_self']:\n",
    "                #    if 'selftext' not in object:\n",
    "                #        continue\n",
    "                try:\n",
    "                    if count == 1:\n",
    "                        self.submission_df = json_normalize(object)\n",
    "                    else:\n",
    "                        df = json_normalize(object)\n",
    "                        self.submission_df = pd.concat([self.submission_df,df],axis = 0,ignore_index = True,sort=False)\n",
    "                except Exception as err:\n",
    "                    print(f\"Couldn't print post: {object['url']}\")\n",
    "                    print(traceback.format_exc())\n",
    "            print(\"Saved {} submissions through {}\".format(count, datetime.fromtimestamp(previous_epoch).strftime(\"%Y-%m-%d\")))\n",
    "        try:\n",
    "            self.submission_df['created_utc'] = pd.to_datetime(self.submission_df['created_utc'],unit='s')\n",
    "            self.submission_df['type'] = 'submission'\n",
    "            columns = ['author','author_fullname','created_utc','full_link','id','is_meta','is_original_content','is_reddit_media_domain','is_robot_indexable','is_self','is_video','media_only','num_comments','num_crossposts','permalink','score','selftext','subreddit','subreddit_id','subreddit_subscribers','subreddit_type','thumbnail','title','url','crosspost_parent','promoted','media.type']\n",
    "            self.submission_df = self.submission_df.reindex(columns = columns)\n",
    "        except:\n",
    "            print('No DF for Submissions!')\n",
    "        #self.submission_df.to_csv(self.filename_submission,index = False)\n",
    "    def create_files(self):\n",
    "        #comments\n",
    "        print('Saving Comments')\n",
    "        cdate_min = str(np.min(self.comment_df['created_utc']))\n",
    "        cdate_max = str(np.max(self.comment_df['created_utc']))\n",
    "        comment_stuff = [self.company,self.keyword,'comments',cdate_min,cdate_max]\n",
    "        comments_files = '-'.join(comment_stuff )\n",
    "        self.comment_df.to_csv(os.path.join(self.directory_comments,comments_files),index = False)\n",
    "        print('Saved Comments')\n",
    "        #Posts\n",
    "        pdate_min = str(np.min(self.submission_df['created_utc']))\n",
    "        pdate_max = str(np.max(self.submission_df['created_utc']))\n",
    "        submission_stuff = [self.company,self.keyword,'posts',pdate_min,pdate_max]\n",
    "        submission_file = '-'.join(submission_stuff)\n",
    "        self.submission_df.to_csv(os.path.join(self.directory_posts,submission_file),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_PushShift(keyword,company,last_comment,last_submission):\n",
    "    print(keyword)\n",
    "    print(last_comment)\n",
    "    print(last_submission)\n",
    "    #Associate Variables\n",
    "    Test = PushShiftPull()\n",
    "    Test.company = company\n",
    "    Test.keyword = keyword\n",
    "    Test.last_comment = last_comment\n",
    "    Test.last_submission = last_submission\n",
    "    #Run Code\n",
    "    Test.create_directories()\n",
    "    Test.downloadFromUrl_comment()\n",
    "    Test.downloadFromUrl_submission()\n",
    "    Test.create_files()\n",
    "    return(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Game Stop\"\n",
      "2020-10-01 00:00:00\n",
      "2020-10-01 00:00:00\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1611727067\n",
      "no break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:52: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 comments through 2021-01-22\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1611350001\n",
      "no break\n",
      "Saved 200 comments through 2021-01-21\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1611271597\n",
      "no break\n",
      "Saved 300 comments through 2021-01-19\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1611092092\n",
      "no break\n",
      "Saved 400 comments through 2021-01-16\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1610816177\n",
      "no break\n",
      "Saved 500 comments through 2021-01-14\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1610640916\n",
      "no break\n",
      "Saved 600 comments through 2021-01-01\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1609558033\n",
      "no break\n",
      "Saved 700 comments through 2020-12-18\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1608330531\n",
      "no break\n",
      "Saved 800 comments through 2020-12-02\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1606942863\n",
      "no break\n",
      "Saved 900 comments through 2020-10-26\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1603685320\n",
      "no break\n",
      "Saved 1000 comments through 2020-10-08\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1602182339\n",
      "no break\n",
      "Saved 1010 comments through 2020-10-05\n",
      "https://api.pushshift.io/reddit/comment/search?q=\"Game Stop\"&limit=1000&subreddit=wallstreetbets&sort=desc&after=1601524800&before=1601895435\n",
      "got json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:97: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:99: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 submissions through 2020-10-18\n",
      "got json\n",
      "Saved 102 submissions through 2020-10-12\n",
      "got json\n"
     ]
    }
   ],
   "source": [
    "Avery = Run_PushShift(keyword,company,date,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fireball5-</td>\n",
       "      <td>t2_2utjiar2</td>\n",
       "      <td>GAME STOP</td>\n",
       "      <td>2021-01-24 12:02:29</td>\n",
       "      <td>gkjjtx1</td>\n",
       "      <td>t3_l3y4mp</td>\n",
       "      <td>t1_gkjj9c2</td>\n",
       "      <td>/r/wallstreetbets/comments/l3y4mp/gme_squeeze_...</td>\n",
       "      <td>20</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kasperdodo</td>\n",
       "      <td>t2_58we8puy</td>\n",
       "      <td>bruh why y'all investing in game stop all of s...</td>\n",
       "      <td>2021-01-24 11:36:12</td>\n",
       "      <td>gkjfuq6</td>\n",
       "      <td>t3_l3onms</td>\n",
       "      <td>t3_l3onms</td>\n",
       "      <td>/r/wallstreetbets/comments/l3onms/ryan_cohen_d...</td>\n",
       "      <td>-2</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kvla1</td>\n",
       "      <td>t2_54iayt2b</td>\n",
       "      <td>I agree on the short squeeze. Applying chewy s...</td>\n",
       "      <td>2021-01-24 11:34:54</td>\n",
       "      <td>gkjfl5w</td>\n",
       "      <td>t3_l2wx2p</td>\n",
       "      <td>t1_gkjewrv</td>\n",
       "      <td>/r/wallstreetbets/comments/l2wx2p/weekend_disc...</td>\n",
       "      <td>2</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chinaisasshole</td>\n",
       "      <td>t2_33qnoq33</td>\n",
       "      <td>If this going to be the next game stop plz tel...</td>\n",
       "      <td>2021-01-24 08:04:50</td>\n",
       "      <td>gkih07h</td>\n",
       "      <td>t3_l3nmk8</td>\n",
       "      <td>t3_l3nmk8</td>\n",
       "      <td>/r/wallstreetbets/comments/l3nmk8/wtf_is_going...</td>\n",
       "      <td>0</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grymninja</td>\n",
       "      <td>t2_9bcif</td>\n",
       "      <td>Yeah well every game stop OTM weekly call for ...</td>\n",
       "      <td>2021-01-24 06:41:06</td>\n",
       "      <td>gki5cvv</td>\n",
       "      <td>t3_l3re7i</td>\n",
       "      <td>t1_gkhuxow</td>\n",
       "      <td>/r/wallstreetbets/comments/l3re7i/i_present_to...</td>\n",
       "      <td>3</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>by_any_other_names</td>\n",
       "      <td>t2_bdshoi</td>\n",
       "      <td>If your in game stop you deserve to lose money</td>\n",
       "      <td>2020-10-08 17:09:53</td>\n",
       "      <td>g84jprt</td>\n",
       "      <td>t3_j7agfu</td>\n",
       "      <td>t1_g84j83w</td>\n",
       "      <td>/r/wallstreetbets/comments/j7agfu/daily_discus...</td>\n",
       "      <td>1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>omgitsdoxa</td>\n",
       "      <td>t2_nqedt</td>\n",
       "      <td>Game stop?</td>\n",
       "      <td>2020-10-07 17:29:38</td>\n",
       "      <td>g80t1n8</td>\n",
       "      <td>t3_j6uoi5</td>\n",
       "      <td>t1_g80q16l</td>\n",
       "      <td>/r/wallstreetbets/comments/j6uoi5/in_search_of...</td>\n",
       "      <td>1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>NeverOddOreveN69</td>\n",
       "      <td>t2_774neusp</td>\n",
       "      <td>Shoulda bought game stop!\\n\\nMuch love!</td>\n",
       "      <td>2020-10-06 20:46:31</td>\n",
       "      <td>g7xpckc</td>\n",
       "      <td>t3_j6ccxn</td>\n",
       "      <td>t3_j6ccxn</td>\n",
       "      <td>/r/wallstreetbets/comments/j6ccxn/how_i_earned...</td>\n",
       "      <td>2</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Fontec</td>\n",
       "      <td>t2_jmfk7</td>\n",
       "      <td>positions spy puts and game stop covered puts</td>\n",
       "      <td>2020-10-06 17:04:00</td>\n",
       "      <td>g7wtt6f</td>\n",
       "      <td>t3_j68vng</td>\n",
       "      <td>t3_j68vng</td>\n",
       "      <td>/r/wallstreetbets/comments/j68vng/tracking_the...</td>\n",
       "      <td>1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Knocker456</td>\n",
       "      <td>t2_6fe46</td>\n",
       "      <td>Can they even afford to buy steam? I would thi...</td>\n",
       "      <td>2020-10-05 10:57:16</td>\n",
       "      <td>g7rxd8w</td>\n",
       "      <td>t3_j5do1u</td>\n",
       "      <td>t1_g7re1ml</td>\n",
       "      <td>/r/wallstreetbets/comments/j5do1u/the_bullish_...</td>\n",
       "      <td>1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author author_fullname  \\\n",
       "0             Fireball5-     t2_2utjiar2   \n",
       "1             kasperdodo     t2_58we8puy   \n",
       "2                  kvla1     t2_54iayt2b   \n",
       "3         chinaisasshole     t2_33qnoq33   \n",
       "4              Grymninja        t2_9bcif   \n",
       "...                  ...             ...   \n",
       "1005  by_any_other_names       t2_bdshoi   \n",
       "1006          omgitsdoxa        t2_nqedt   \n",
       "1007    NeverOddOreveN69     t2_774neusp   \n",
       "1008              Fontec        t2_jmfk7   \n",
       "1009          Knocker456        t2_6fe46   \n",
       "\n",
       "                                                   body         created_utc  \\\n",
       "0                                             GAME STOP 2021-01-24 12:02:29   \n",
       "1     bruh why y'all investing in game stop all of s... 2021-01-24 11:36:12   \n",
       "2     I agree on the short squeeze. Applying chewy s... 2021-01-24 11:34:54   \n",
       "3     If this going to be the next game stop plz tel... 2021-01-24 08:04:50   \n",
       "4     Yeah well every game stop OTM weekly call for ... 2021-01-24 06:41:06   \n",
       "...                                                 ...                 ...   \n",
       "1005     If your in game stop you deserve to lose money 2020-10-08 17:09:53   \n",
       "1006                                         Game stop? 2020-10-07 17:29:38   \n",
       "1007            Shoulda bought game stop!\\n\\nMuch love! 2020-10-06 20:46:31   \n",
       "1008      positions spy puts and game stop covered puts 2020-10-06 17:04:00   \n",
       "1009  Can they even afford to buy steam? I would thi... 2020-10-05 10:57:16   \n",
       "\n",
       "           id    link_id   parent_id  \\\n",
       "0     gkjjtx1  t3_l3y4mp  t1_gkjj9c2   \n",
       "1     gkjfuq6  t3_l3onms   t3_l3onms   \n",
       "2     gkjfl5w  t3_l2wx2p  t1_gkjewrv   \n",
       "3     gkih07h  t3_l3nmk8   t3_l3nmk8   \n",
       "4     gki5cvv  t3_l3re7i  t1_gkhuxow   \n",
       "...       ...        ...         ...   \n",
       "1005  g84jprt  t3_j7agfu  t1_g84j83w   \n",
       "1006  g80t1n8  t3_j6uoi5  t1_g80q16l   \n",
       "1007  g7xpckc  t3_j6ccxn   t3_j6ccxn   \n",
       "1008  g7wtt6f  t3_j68vng   t3_j68vng   \n",
       "1009  g7rxd8w  t3_j5do1u  t1_g7re1ml   \n",
       "\n",
       "                                              permalink  score  \\\n",
       "0     /r/wallstreetbets/comments/l3y4mp/gme_squeeze_...     20   \n",
       "1     /r/wallstreetbets/comments/l3onms/ryan_cohen_d...     -2   \n",
       "2     /r/wallstreetbets/comments/l2wx2p/weekend_disc...      2   \n",
       "3     /r/wallstreetbets/comments/l3nmk8/wtf_is_going...      0   \n",
       "4     /r/wallstreetbets/comments/l3re7i/i_present_to...      3   \n",
       "...                                                 ...    ...   \n",
       "1005  /r/wallstreetbets/comments/j7agfu/daily_discus...      1   \n",
       "1006  /r/wallstreetbets/comments/j6uoi5/in_search_of...      1   \n",
       "1007  /r/wallstreetbets/comments/j6ccxn/how_i_earned...      2   \n",
       "1008  /r/wallstreetbets/comments/j68vng/tracking_the...      1   \n",
       "1009  /r/wallstreetbets/comments/j5do1u/the_bullish_...      1   \n",
       "\n",
       "           subreddit subreddit_id  subreddit_name_prefixed  subreddit_type  \\\n",
       "0     wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "1     wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "2     wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "3     wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "4     wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "...              ...          ...                      ...             ...   \n",
       "1005  wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "1006  wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "1007  wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "1008  wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "1009  wallstreetbets     t5_2th52                      NaN             NaN   \n",
       "\n",
       "      total_awards_received     type  \n",
       "0                         0  comment  \n",
       "1                         0  comment  \n",
       "2                         0  comment  \n",
       "3                         0  comment  \n",
       "4                         0  comment  \n",
       "...                     ...      ...  \n",
       "1005                      0  comment  \n",
       "1006                      0  comment  \n",
       "1007                      0  comment  \n",
       "1008                      0  comment  \n",
       "1009                      0  comment  \n",
       "\n",
       "[1010 rows x 15 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avery.comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
